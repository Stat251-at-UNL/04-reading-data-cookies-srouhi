---
title: "Chocolate Chip Cookies"
execute:
  error: true
author: "Shay Rouhi"
output: html_document
---

## Reading In the Data

First, read in the CSV data of cookie ingredients.
Make sure that your end-result data has appropriate types for each column - these should match the types provided in the documentation in the README.md file.

```{r}
df <- read.csv("choc_chip_cookie_ingredients.csv")
#head(df)
```

```{python}
import pandas as pd
df = pd.read_csv("choc_chip_cookie_ingredients.csv")
#print(df.head())
```


## Exploratory Data Analysis

Exploratory data analysis is the process of getting familiar with your dataset. To get started, [this blog post](https://www.mrdbourke.com/a-gentle-introduction-to-exploratory-data-analysis/) provides a nice checklist to get you thinking:

> 1.  What question(s) are you trying to solve (or prove wrong)?
> 2.  What kind of data do you have and how do you treat different types?
> 3.  What's missing from the data and how do you deal with it?
> 4.  Where are the outliers and why should you care about them?
> 5.  How can you add, change or remove features to get more out of your data?

### Generating Questions

Generate at least 5 questions you might explore using this database of cookie ingredients.

1. What ingredients are most commonly used in chocolate chip cookie recipes?
2. How do the ingredient quantities for the same ingredients change between different recipes?
3. Is there a connection between ingredients used and the recipe's rank?
4. which ingredients show the most variability of quantity across recipes?
5. Are there missing values or zeros in 'Quantity'? 


### Skimming the Data

One thing we often want to do during EDA is to examine the quality of the data - are there missing values? What quirks might exist in the dataset?

The `skimr` package in R, and the similar `skimpy` package in python (which has a much better name, in my opinion), can help provide visual summaries of the data. 

Install both packages, and read the package documentation ([R](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html), [Python](https://pypi.org/project/skimpy/)).

[Part 1] Use each package and generate summaries of your data that require the use of at least some non-default options in each package's `skim` function.


```{r}
library(skimr)
skim(df)
```

```{python}
from skimpy import skim
skim(df)

```

[Part 2] Write 1-2 sentences about what you can tell from each summary display you generate. Did you discover anything new about the data? 

R: skimr --> based on this result we see that the data has 1990 rows and 7 columns, it also contains a mix of characters and numeric values. One thing that really stood out to me is the large number of missing values in 'Rating', while 'Quantity' has no missing value.  

Python: skimpy --> it basically shows the same thing as skimr, just the formatting is a little different (prettier in my opinion), the additional thing in skimpy is showing the distribution details like right skewed distribution of 'Quantity'. It also shows that there is a wide variation of text length for ingredient descriptions, which means there are differences in how detailed instructions are.  


### Generating Tables

Another useful technique for exploratory data analysis is to generate summary tables. 
You may want to use the `dplyr` package in R (`group_by` or `count` functions), as well as the `groupby` and `count` methods in Pandas. [Python example](https://sparkbyexamples.com/pandas/pandas-groupby-count-examples/), [R example](https://dplyr.tidyverse.org/reference/count.html)

[Part 1] Using R and Python, generate a table that shows what **proportion** of recipes contain each type of ingredient, for the most common 20 ingredients.

```{R}
library(dplyr)
common_20 <- df |> 
  distinct(Ingredient, Recipe_Index) |>
  count(Ingredient, sort = TRUE) |> #count and sort # of recipes w/ ingredients (n)
  mutate(Proportion = n / n_distinct(df$Recipe_Index)) |> #new col: each ingredient count / total unique recipes
  slice_head(n=20)
#for each ingredients, count how many distinct Recipe_Index
common_20

```


```{Python}
import pandas as pd
df = pd.read_csv("choc_chip_cookie_ingredients.csv") #I had to rerun this 
ingredientCounts = (
    df.groupby('Ingredient')['Recipe_Index'].nunique() #group by ingredient and then for each, count number of unique recipe_index
      .reset_index(name='RecipeCount') #convert back to df w/ a new name
)

total = df['Recipe_Index'].nunique()
ingredientCounts['Proportion'] = (
    ingredientCounts['RecipeCount'] / total
) #col proportion: divide recipes having each ingredient by total recipes

# most common 20 - sort then take top 20
common_20 = ingredientCounts.sort_values(
    by='Proportion', ascending=False
).head(20)

print(common_20)
```


[Part 2] Print out a character string that lists all of the ingredients that do not appear in at least 20 recipes.

```{R}
least_20 <- df |> 
  distinct(Ingredient, Recipe_Index) |>
  count(Ingredient, sort = TRUE) |>
  slice(-1:-20) |> #same as above but here after top 20
  pull(Ingredient) |> #extract Ingredient col only
  paste(collapse = ",")
least_20

```

```{Python}
#basically same as above except the common 20 and converting to string
#for this part we could've used previous code directly but I was having with python here so I wrote the entire thing again.
import pandas as pd
df = pd.read_csv("choc_chip_cookie_ingredients.csv") #I had to rerun this 
ingredientCounts = (
    df.groupby('Ingredient')['Recipe_Index'].nunique() 
      .reset_index(name='RecipeCount') 
)

total = df['Recipe_Index'].nunique()
ingredientCounts['Proportion'] = (
    ingredientCounts['RecipeCount'] / total
)
least_20 = ingredientCounts.sort_values(
    by='Proportion', ascending=False
).iloc[20:] #only this part diff
least_20_str = ",".join(least_20['Ingredient'])

print(least_20_str)
```

(Delete this note, but you can include data values inline in markdown text by using backticks, at least in R. For instance, here is R's built in value for pi: `r pi`. Unfortunately, this doesn't work in python using the knitr markdown engine, but you can print the list out in python anyways using a code chunk.)

### Visualization

Using whatever plotting system you are comfortable with in R or python, see if you can create a couple of useful exploratory data visualizations which address one of the questions you wrote above - or another question which you've come up with as you've worked on this assignment.

[Part 1] Create at least one plot (it doesn't have to be pretty) that showcases an interesting facet of the data.

```{R}

#I'm going with bar chart for common_20
library(ggplot2)
ggplot(common_20, aes(x= reorder(Ingredient, Proportion), y=Proportion)) +
  geom_col(fill = "blue")+
  coord_flip() +
  labs(
    title = "most common 20 ingredients",
    x = "ingredients",
    y = "recipe proportion"
  )
```

```{Python}
##I'm having trouble with python, so I have to include the previous part of code again- but it's repeated similar to earlier.
import pandas as pd
df = pd.read_csv("choc_chip_cookie_ingredients.csv")
ingredientCounts = (
    df.groupby('Ingredient')['Recipe_Index'].nunique()
      .reset_index(name='RecipeCount') )
total = df['Recipe_Index'].nunique()
ingredientCounts['Proportion'] = (
    ingredientCounts['RecipeCount'] / total)
common_20 = ingredientCounts.sort_values(
    by='Proportion', ascending=False
).head(20)

#######
# added part - visualization:

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
sns.barplot(
    data=common_20,
    y='Ingredient', x='Proportion',
    palette='Blues'
)
plt.title("Top 20 Ingredients by Proportion of Recipes")
plt.xlabel("Proportion of Recipes")
plt.ylabel("Ingredient")
plt.show()



```


[Part 2] Write 2-3 sentences about what you can learn from that plot and what directions you might want to investigate from here.

Both plots show the most common 20 ingredients used in chocolate chip cookie recipes. some ingredients like egg, vanilla, all-purpose flour are almost in all of recipes (which makes sense), and on the other hand, some ingredients like peacon and dark chocolate chip cookies are common but much less common than those. 
From here, we can look into ingredient combinations. For example what combination of ingredients are used more and more common to be paired. We can also look for patterns between rating and certain ingredients, for example does use of less common ingredient impact the rating? or if we remove the top-k ingredients what other (less common) ingredients improve the ranking of a recipe?
Another approach is to explore 'Quantity' more, for example quantity vs recipe rating, or visualize how quantities vary between the top 20 recipes, or look into outliers and recipes with unusually high/low quantities of essential ingredients.  


